# ‚úÖ Cortex API Integration - Complete!

## üéâ What Changed

I've updated your application to work with the **Lilly Cortex API**!

### Key Updates

#### 1. AI Service (`server/services/aiService.js`)
- ‚úÖ Changed from `application/x-www-form-urlencoded` to `multipart/form-data`
- ‚úÖ Using `FormData` for request body
- ‚úÖ Added session ID support (`model_session_id_param`) for conversation history
- ‚úÖ Increased timeout to 120 seconds (Cortex can take longer)
- ‚úÖ Proper response parsing for Cortex format: `{ message: "...", ... }`
- ‚úÖ Cookie authentication (optional, already configured)

#### 2. Environment Configuration (`server/.env`)
- ‚úÖ **MODEL_ENDPOINT**: `https://dev.cortex.lilly.com/model/ask/poc-conversational-text-editor-agent`
- ‚úÖ **COOKIE**: Your authentication cookie (already set)
- ‚úÖ **PORT**: 5000

#### 3. Dependencies (`server/package.json`)
- ‚úÖ Added `form-data` package for multipart/form-data support

#### 4. Conversation Routes (`server/routes/conversation.js`)
- ‚úÖ Passes session ID to Cortex for conversation history tracking
- ‚úÖ Cortex handles the conversation context automatically

---

## üîß Cortex API Integration Details

### Request Format

```javascript
POST https://dev.cortex.lilly.com/model/ask/poc-conversational-text-editor-agent
Content-Type: multipart/form-data

Parameters:
- q: "User's message"
- model_session_id_param: "unique-session-id"
- stream: false
- use_responses_api: false
- no_summary: false
- workflow_timeout: 1800
- background_job: false
```

### Response Format

```json
{
  "message": "AI assistant's response...",
  "source_metadata": [],
  "steps": [
    {
      "name": "Model",
      "message": "# Starting model chain...",
      "status": "running",
      "parent": "root"
    }
  ],
  "status": [],
  "state_params": {}
}
```

The application extracts the `message` field from the response.

### Session Management

- Each conversation gets a unique session ID
- Format: `conv_<timestamp>_<random>`
- Cortex uses this to maintain conversation history
- No need to manually send chat history - Cortex handles it!

---

## üöÄ Ready to Run!

Your application is **fully configured** and ready to use!

### Start the Servers

**Terminal 1 - Backend:**
```bash
cd "C:\Users\SaiSubinSV\OneDrive - CHIMERA TECHNOLOGIES PVT LTD\lilly\smart product profile\text editor poc\server"
npm run dev
```

**Terminal 2 - Frontend:**
```bash
cd "C:\Users\SaiSubinSV\OneDrive - CHIMERA TECHNOLOGIES PVT LTD\lilly\smart product profile\text editor poc\client"
npm start
```

### Expected Output

**Backend Server:**
```
üöÄ Server running on http://localhost:5000
üìù Text Editor POC Backend

üìã Available endpoints:
   GET  /health - Health check
   POST /api/conversation/message - Send message to AI
   POST /api/conversation/reset - Reset conversation
   GET  /api/conversation/status - Check AI service status

‚öôÔ∏è  Environment:
   PORT: 5000
   MODEL_ENDPOINT: ‚úÖ Configured
   COOKIE: ‚úÖ Configured
```

**Frontend:**
- Opens automatically at `http://localhost:3000`
- Shows split-screen interface
- Empty editor (left) + welcome message (right)

---

## üéØ How It Works

### User Flow

1. **User sends message**: "I want to build a fraud detection system"

2. **Frontend ‚Üí Backend**: 
   ```javascript
   POST /api/conversation/message
   { message: "...", conversationId: "conv_123..." }
   ```

3. **Backend ‚Üí Cortex**:
   ```javascript
   POST /model/ask/poc-conversational-text-editor-agent
   FormData: {
     q: "I want to build a fraud detection system",
     model_session_id_param: "conv_123..."
   }
   ```

4. **Cortex ‚Üí Backend**:
   ```json
   {
     "message": "Excellent! Fraud detection is critical...",
     "steps": [...]
   }
   ```

5. **Backend ‚Üí Frontend**:
   ```json
   {
     "conversationId": "conv_123...",
     "message": "Excellent! Fraud detection is critical...",
     "timestamp": "2026-02-03T..."
   }
   ```

6. **Frontend**:
   - Displays AI message in chat
   - Extracts document content
   - Updates text editor

### Conversation History

- Cortex maintains history using `model_session_id_param`
- Each conversation has a unique session ID
- History persists across multiple requests
- Reset creates a new session ID

---

## üìã System Prompt

The Cortex model should be configured with the prompt from [`SYSTEM_PROMPT.md`](file:///C:/Users/SaiSubinSV/OneDrive%20-%20CHIMERA%20TECHNOLOGIES%20PVT%20LTD/lilly/smart%20product%20profile/text%20editor%20poc/SYSTEM_PROMPT.md).

**Key Instructions**:
- Warm, professional, encouraging tone
- Extract information from any user input
- Progressively build document sections
- Ask targeted follow-up questions
- Format responses with markdown structure
- Never invent information

---

## üêõ Troubleshooting

### Cookie Expired

**Symptoms**: 401 Unauthorized errors

**Solution**:
1. Get a fresh cookie from your browser
2. Update `server/.env`:
   ```env
   COOKIE=your_new_cookie_here
   ```
3. Restart the backend server

### Cortex API Timeout

**Symptoms**: Request timeout after 120 seconds

**Solution**:
- This is normal for complex queries
- The timeout is already set to 120s (max recommended)
- Consider simplifying the query or breaking it into parts

### No Response from Cortex

**Symptoms**: "No response from Cortex API" error

**Solution**:
1. Check network connectivity
2. Verify the endpoint URL is correct
3. Ensure you're on the Lilly network (VPN if remote)
4. Check Cortex service status

### Session Not Persisting

**Symptoms**: AI doesn't remember previous messages

**Solution**:
- Verify `conversationId` is being sent in requests
- Check backend logs for session ID
- Ensure Cortex model supports session management

---

## üìÅ Updated Files

| File | Changes |
|------|---------|
| `server/services/aiService.js` | Updated to use multipart/form-data, session IDs, Cortex response format |
| `server/routes/conversation.js` | Added session ID parameter to AI service calls |
| `server/package.json` | Added `form-data` dependency |
| `server/.env` | Configured with Cortex endpoint and cookie |
| `README.md` | Updated with Cortex API details |
| `GETTING_STARTED.md` | Simplified to show app is ready to run |
| `QUICK_START.md` | New quick reference guide |

---

## ‚úÖ Summary

Your conversational text editor is **fully integrated** with the Lilly Cortex API and ready to use!

**What's Working**:
- ‚úÖ Cortex API integration with multipart/form-data
- ‚úÖ Session-based conversation history
- ‚úÖ Cookie authentication
- ‚úÖ Intelligent document extraction
- ‚úÖ Progressive document building
- ‚úÖ Modern split-screen UI
- ‚úÖ All dependencies installed

**Next Steps**:
1. Start both servers (backend + frontend)
2. Open `http://localhost:3000`
3. Start drafting AI project proposals!

---

**üéä Everything is ready! Just run the servers and start using your app!**
